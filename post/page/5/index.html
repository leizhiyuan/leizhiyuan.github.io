<!doctype html><html lang=zh-cn><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><title>Posts | bystander's blog</title><meta property="og:title" content="Posts - bystander's blog"><meta property="og:type" content="article"><meta name=Keywords content><meta name=description content="Posts"><meta name=author content="bystander"><meta property="og:url" content="http://leaver.me/post/"><link rel="shortcut icon" href=/favicon.ico type=image/x-icon><link rel=stylesheet href=/css/normalize.css><link rel=stylesheet href=/css/style.css><link rel=alternate type=application/rss+xml+xml href=http://leaver.me/post/index.xml title="bystander's blog"><script type=text/javascript src=//cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js></script></head><body><header id=header class=clearfix><div class=container><div class=col-group><div class=site-name><a id=logo href=http://leaver.me/>bystander's blog</a><p class=description>寻找窄门</p></div><div><nav id=nav-menu class=clearfix><a class=current href=http://leaver.me/>首页</a>
<a href=http://leaver.me/categories title=目录>目录</a>
<a href=http://leaver.me/about/ title=关于我>关于我</a></nav></div></div></div></header><div id=body><div class=container><div class=col-group><div class=col-8 id=main><div class=res-cons><article class=post><header><h1 class=post-title><a href=http://leaver.me/2015/11/20/java%E5%8F%AF%E9%87%8D%E5%85%A5%E9%94%81%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/ title=Java可重入锁学习笔记>Java可重入锁学习笔记</a></h1></header><date class="post-meta meta-date">2015年11月20日</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=http://leaver.me/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0>学习笔记</a></span></div><div class=post-content>前几天被前辈问到这个可重入锁,结果忘掉了.于是抽空整个了解一下
目录 什么是可重入锁 为什么要可重入 如何实现可重入锁 有不可重入锁吗 demo代码展示 参考文章 1 . 什么是可重入锁 锁的概念就不用多解释了,当某个线程A已经持有了一个锁,当线程B尝试进入被这个锁保护的代码段的时候.就会被阻塞.而锁的操作粒度是"线程&rdquo;,而不是调用(至于为什么要这样,下面解释).同一个线程再次进入同步代码的时候.可以使用自己已经获取到的锁,这就是可重入锁 java里面内置锁(synchronize)和Lock(ReentrantLock)都是可重入的
2 . 为什么要可重入 如果线程A继续再次获得这个锁呢?比如一个方法是synchronized,递归调用自己,那么第一次已经获得了锁,第二次调用的时候还能进入吗? 直观上当然需要能进入.这就要求必须是可重入的.可重入锁又叫做递归锁,再举个例子.
public class Widget { public synchronized void doSomething() { ... } } public class LoggingWidget extends Widget { public synchronized void doSomething() { System.out.println(toString() + ": calling doSomething"); super.doSomething();//若内置锁是不可重入的，则发生死锁 } } 这个例子是java并发编程实战中的例 子.synchronized 是父类Widget的内置锁,当执行子 类的方法的时候,先获取了一次Widget的锁,然后在执行super的时候,就要获取一次,如果不可重入,那么就跪了.
3 . 如何实现可重入锁 为每个锁关联一个获取计数器和一个所有者线程,当计数值为0的时候,这个所就没有被任何线程只有.当线程请求一个未被持有的锁时,JVM将记下锁的持有者,并且将获取计数值置为1,如果同一个线程再次获取这个锁,技术值将递增,退出一次同步代码块,计算值递减,当计数值为0时,这个锁就被释放. ReentrantLock里面有实现
4 . 有不可重入锁吗 这个还真有.Linux下的pthread_mutex_t锁是默认是非递归的。可以通过设置PTHREAD_MUTEX_RECURSIVE属性，将pthread_mutex_t锁设置为递归锁。如果要自己实现不可重入锁,同可重入锁,这个计数器只能为1.或者0,再次进入的时候,发现已经是1了,就进行阻塞.jdk里面没有默认的实现类.
5 . demo代码展示 5.1 内置锁的可重入
public class ReentrantTest { public void method1() { synchronized (ReentrantTest.class) { System.out.println("方法1获得ReentrantTest的内置锁运行了"); method2(); } } public void method2() { synchronized (ReentrantTest.class) { System.out.println("方法1里面调用的方法2重入内置锁,也正常运行了"); } } public static void main(String[] args) { new ReentrantTest().method1(); } } 5.2 lock对象的可重入
import java.util.concurrent.locks.Lock; import java.util.concurrent.locks.ReentrantLock; public class ReentrantLockTest { private Lock lock = new ReentrantLock(); public void method1() { lock.lock(); try { System.out.println("方法1获得ReentrantLock锁运行了"); method2(); } finally { lock.unlock(); } } public void method2() { lock.lock(); try { System.……</div><p class=readmore><a href=http://leaver.me/2015/11/20/java%E5%8F%AF%E9%87%8D%E5%85%A5%E9%94%81%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/>阅读全文</a></p></article><article class=post><header><h1 class=post-title><a href=http://leaver.me/2015/09/12/%E4%BA%8B%E5%8A%A1%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/ title=事务学习笔记>事务学习笔记</a></h1></header><date class="post-meta meta-date">2015年9月12日</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=http://leaver.me/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0>学习笔记</a></span></div><div class=post-content>最近有个感受,在实践中学习固然重要,但是实践遇到的问题常常并没有想象的那么多,而且并不能覆盖所有的情况,所以还是需要对理论有一些深入的理解
什么是事务 事务指的是逻辑上的一组操作,这组操作要么全部成功,要么全部失败,不允许出现部分成功的情况.
事务的特性 定义了事务之后,事务四个特性
原子性 事务是不可分割的单位,事务中的这组操作要么都发生,要么都不发生. 一致性 一致性说是事务执行前后必须要保持一致,不能出现凭空消失的情况,典型的如银行转账的操作,A给B转账,如果刚开始两人总共有100元,转账完成后两人总共还要有100元. 隔离性 多个用户并发访问数据库的时候,一个用户的事务不能被其他的用户的事务所干扰.多个并发事务之间数据要相互隔离.比如事务1,C给A转帐,此时事务2,A给B转账.那么两个事务都要修改A账户的余额,一个增加,一个减少,如何保证他们改完之后数据是对的.这是隔离性的要求. 持久性 一旦事务被提交,对数据库的改变就是持久性的.即使数据库发生故障也不应该有任何影响. 事务的隔离级别 为什么要有隔离级别呢,因为如果没有隔离级别,当两个事务同时对某条记录进行操作的时候,可能会出现如下几种大家常常听到的情况.
1 脏读 脏读就是指当一个事务正在访问数据，并且对数据进行了修改，而这种修改还没有提交到数据库中，这时，另外一个事务也访问这个数据，然后使用了这个数据。
事务1：更新一条数据 ------->事务2：读取事务1更新的记录 事务1：调用commit进行提交 由于事务2使用了事务1还没有提交的记录,如果事务1最后正常提交了还好,但是如果事务1没有提交,而是回滚了.那么事务2的操作就有问题,因为他用的数据是错的.这就是脏读
2 不可重复读 在同一事务中，两次读取同一数据，得到内容不同
事务1：查询一条记录 ————–>事务2：更新事务1查询的记录 ————–>事务2：调用commit进行提交 事务1：再次查询上次的记录 事务1要进行两次查询来做一些比如展示或者使用的操作,但是在两次查询事件被事务2更新掉了记录,所以事务1就出现了不可重复读的问题.
3 幻读 同一事务中，用同样的操作读取两次，得到的记录数不相同
事务1：查询表中所有记录 ————–>事务2：插入一条记录 ————–>事务2：调用commit进行提交 事务1：再次查询表中所有记录 此时事务1两次查询到的记录是不一样的，称为幻读
幻读的重点是新增或者删除,由于另一个事务对表中进行了新增或者删除,到时当前事务每次看到的都条数不一样,就像发生了幻觉一样,查一次多了一条,再查一次,发现又没了.
为此,对事务引入了隔离级别这个概念,由数据库保证 DEFAULT 使用数据库设置的隔离级别 ( 默认 ) ，由 DBA 默认的设置来决定隔离级别 . READ_UNCOMMITTED 会出现脏读、不可重复读、幻读 ( 隔离级别最低，并发性能高 ) READ_COMMITTED 会出现不可重复读、幻读问题（锁定正在读取的行） REPEATABLE_READ 会出幻读（锁定所读取的所有行） SERIALIZABLE 保证所有的情况不会发生（锁表） 可以看到,这四种从上到下性能越来越差,保障性越来越高.
以解决幻读问题为例,SERIALIZABLE直接进行了锁表,那么印发幻读的对该表的插入和删除都无法操作,只能查询.所以不会有问题了..
事务的传播行为 事务的传播行为主要是为了解决事务嵌套调用的问题,比如A方法里面使用了事务操作,B方法里面也使用了事务操作,当A调用B的时候.这个情况是如何处理的呢
1 REQUIRED 业务方法需要在一个事务中运行,如果方法运行时,已处在一个事务中,那么就加入该事务,否则自己创建一个新的事务.这是spring默认的传播行为.
2 SUPPORTS 如果业务方法在某个事务范围内被调用,则方法成为该事务的一部分,如果业务方法在事务范围外被调用,则方法在没有事务的环境下执行.
3 MANDATORY 只能在一个已存在事务中执行,业务方法不能发起自己的事务,如果业务方法在没有事务的环境下调用,就抛异常
4 REQUIRES_NEW 业务方法总是会为自己发起一个新的事务,如果方法已运行在一个事务中,则原有事务被挂起,新的事务被创建,直到方法结束,新事务才结束,原先的事务才会恢复执行. 5 NOT_SUPPORTED 声明方法需要事务,如果方法没有关联到一个事务,容器不会为它开启事务.如果方法在一个事务中被调用,该事务会被挂起,在方法调用结束后,原先的事务便会恢复执行. 6 NEVER 声明方法绝对不能在事务范围内执行,如果方法在某个事务范围内执行,容器就抛异常.只有没关联到事务,才正常执行.
7 NESTED 如果一个活动的事务存在,则运行在一个嵌套的事务中.如果没有活动的事务,则按REQUIRED属性执行.它使用了一个单独的事务, 这个事务拥有多个可以回滚的保证点.内部事务回滚不会对外部事务造成影响, 它只对DataSourceTransactionManager 事务管理器起效.
总共7个,1,4,7最重要.1就是说A和B会在A的事务里.而4是B会开启一个新的事务,直到完成结束,A的事务才会继续运行.
参考资料 Spring事务管理 Innodb中的事务隔离级别和锁的关系 ……</div><p class=readmore><a href=http://leaver.me/2015/09/12/%E4%BA%8B%E5%8A%A1%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/>阅读全文</a></p></article><article class=post><header><h1 class=post-title><a href=http://leaver.me/2015/09/08/kafka%E5%BF%AB%E9%80%9F%E5%BC%80%E5%8F%91demo/ title=kafka快速开发demo>kafka快速开发demo</a></h1></header><date class="post-meta meta-date">2015年9月8日</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=http://leaver.me/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0>学习笔记</a></span></div><div class=post-content>在kafka快速上手,主要是使用kafka提供的测试来做了一下简单测试,实际开发中的使用可能才是我们要关系的.启动zk和kafka,新建topic的过程都不变.
1 新建一个maven工程,引入依赖
&lt;dependency> &lt;groupId>org.apache.kafka&lt;/groupId> &lt;artifactId>kafka_2.11&lt;/artifactId> &lt;version>0.8.2.1&lt;/version> &lt;/dependency> 2 编写配置文件
public interface KafkaProperties { public final static String ZK = "127.0.0.1:2181"; public final static String GROUP_ID = "test_group1"; public final static String TOPIC = "test"; public final static String BROKER_LIST = "127.0.0.1:9092"; public final static String SESSION_TIMEOUT = "20000"; public final static String SYNC_TIMEOUT = "20000"; public final static String INTERVAL = "1000"; } 3 编写生产者
public class KafkaProducer extends Thread { private Producer&lt;Integer, String> producer; private String topic; private Properties props = new Properties(); private final int SLEEP = 1000 * 3; public KafkaProducer(String topic) { props.put("serializer.class", "kafka.serializer.StringEncoder"); //生产者直接和broker列表连接 props.put("metadata.broker.list", KafkaProperties.BROKER_LIST); producer = new Producer&lt;Integer, String>(new ProducerConfig(props)); this.topic = topic; } @Override public void run() { int offsetNo = 1; while (true) { String msg = new String("Message_" + offsetNo); System.out.println("Send->[" + msg + "]"); producer.send(new KeyedMessage&lt;Integer, String>(topic, msg)); offsetNo++; try { sleep(SLEEP); } catch (Exception ex) { ex.……</div><p class=readmore><a href=http://leaver.me/2015/09/08/kafka%E5%BF%AB%E9%80%9F%E5%BC%80%E5%8F%91demo/>阅读全文</a></p></article><article class=post><header><h1 class=post-title><a href=http://leaver.me/2015/09/07/kafka%E6%96%87%E7%AB%A0%E6%8E%A8%E8%8D%90/ title=kafka文章推荐>kafka文章推荐</a></h1></header><date class="post-meta meta-date">2015年9月7日</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=http://leaver.me/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0>学习笔记</a></span></div><div class=post-content>本文主要分享看到的好的关于kafka的文章.后续看到持续更新
Kafka剖析（一）：Kafka背景及架构介绍 Kafka设计解析（二）：Kafka High Availability （上） Kafka设计解析（三）：Kafka High Availability （下） Kafka设计解析（四）：Kafka Consumer解析 ……</div><p class=readmore><a href=http://leaver.me/2015/09/07/kafka%E6%96%87%E7%AB%A0%E6%8E%A8%E8%8D%90/>阅读全文</a></p></article><article class=post><header><h1 class=post-title><a href=http://leaver.me/2015/09/05/kafka%E5%88%86%E5%B8%83%E5%BC%8F%E9%83%A8%E7%BD%B2%E4%B8%8E%E9%AA%8C%E8%AF%81/ title=kafka分布式部署与验证>kafka分布式部署与验证</a></h1></header><date class="post-meta meta-date">2015年9月5日</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=http://leaver.me/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0>学习笔记</a></span></div><div class=post-content>在kafka快速上手,和kafka中的partition和offset中,已经解释了kafka的一些原理,和完成了一个简单的生产消费的实践,如第一篇所说,kafka是一个分布式环境下的消息组件,那么,按照我们前面的简单上手,如果kafka的应用进程被杀或者kafka的机器宕机,那么kafka消息组件就无法使用了,或者zookeeper宕机了,那么kafka也无法使用了.
kafka集群(cluster) 一台机器不够,那就多搞几台,首先,启动zookeeper这个就不多说了.可以参看前文,在启动kafka的时候,我们在单机模拟启动多个kafka应用. 首先在config目录,copy两个server.properties 文件,这里我复制三份,分别起名server1.properties ,server2.properties server3.properties 然后修改这三个配置文件,主要修改broker.id=2,port=9094,log.dir=/tmp/kafka-logs-2这三个值,broker.id是用来标记分布式环境中的broker的,要求唯一,port和log.dir一个端口,一个log目录,如果在真实的分布式环境中是不需要修改.这里单机模拟防止端口冲突.
分别把broker.id改为1,2,3,log.dir则分别改成kafka-logs-1,kafka-logs-2,kafka-logs-3,然后依次启动 kafka-server-start.bat ../../config/server1.properties kafka-server-start.bat ../../config/server2.properties kafka-server-start.bat ../../config/server3.properties
如果你启动有报错,一个就是之前说的那个vm参数太大,另一个可能是你的端口没改好.具体错误看下报错就好了.
然后我们注册一个topic,叫做replicationtest kafka-topics.bat --create --zookeeper localhost:2181 --replication-factor 3 --partitions 1 --topic replicationtest 这里冗余是3,分区是1,那么最终各个broker都会保留一份,最多允许N-1,也就是2台broker宕机,服务照样运行. 注册之后,这时候 kafka-topics.bat--describe --zookeeper localhost:2181 --topic replicationtest 执行描述命令,看下集群情况 第一行给出了分区的汇总信息。每个分区行给出分区信息。
&ldquo;Leader&rdquo; 节点是2. &ldquo;Replicas&rdquo; 信息，在节点2,3,1上,所有的节点信息. &ldquo;Isr&rdquo; 工作中的复制节点的集合. 也就是活的节点的集合.
其他的就不用解释了.这里选出了2是leader,也就是说2这个节点会给消费者提供服务.
然后我们测试一条信息. kafka-console-producer.bat --broker-list localhost:7777,localhost:8888,localhost:9999 --topic replicationtest 上面的7777是server1.properties 中设置的.根据个人情况.改改.然后在控制台发发消息.
然后消费一下. kafka-console-consumer.bat --zookeeper localhost:2181 --topic replicationtest 这里的2181是zookeeper的端口,不用改. 然后.我们开始关掉一个broker,在3的控制台里CTRL,C.然后是否终止操作,输入Y. 再发一条消息 一切正常.我们看一下集群信息 发现Isr中存活的机器少了3.因为3挂了. 然后我们关掉broker2.这时候,会触发新的leader选举.期望值1变成leader,再发一条消息 可以看到生产者发消息过程中,产生了异常,因为和2的连接断开了.但是注意,消息并没有丢,因为触发了新的选举.可以看到,消费者还是接到了正常的消息.集群情况如下 至此,kafka的broker集群测试完毕,那么剩下的问题来了.消费者启动的时候连接的是zookeeper的地址,如果这台zookeeper挂了呢. 那么我们需要zookeeper集群部署.
zookeeper集群 这就包括两部分.
是broker本来要能知道这些zookeeper集群的地址,当一个宕机的时候,才会切换到另一个zookeeper 消费者要知道这些zookeeper的地址,理由同上. 因此步骤如下.可以自己试一试,比较简单
复制3份zookeeper.properties文件,命名为zookeeper1.properties,zookeeper2.properties,zookeeper3.properties,修改文件中的dataDir=/tmp/zookeeper和,clientPort=2181,端口分别设置为2181,2182,2183.然后启动三个zookeeper 修改kafka启动配置,server1.properties三个文件中的zookeeper.connect=localhost:2181这个配置,逗号隔开.最终为zookeeper.connect=localhost:2181,localhost:2182,localhost:2183,然后启动 生产者也改下配置中的.metadata.broker.list=localhost:9092,如果使用命令行启动就不用改了.参数指定也可以. 消费者同理,可以改下配置文件中zookeeper.connect=127.0.0.1:2181,也可以命令行启动的时候修改. 5.最终就是各种宕机测试了. ……</div><p class=readmore><a href=http://leaver.me/2015/09/05/kafka%E5%88%86%E5%B8%83%E5%BC%8F%E9%83%A8%E7%BD%B2%E4%B8%8E%E9%AA%8C%E8%AF%81/>阅读全文</a></p></article><article class=post><header><h1 class=post-title><a href=http://leaver.me/2015/09/04/kafka%E4%B8%AD%E7%9A%84partition%E5%92%8Coffset/ title=kafka中的partition和offset>kafka中的partition和offset</a></h1></header><date class="post-meta meta-date">2015年9月4日</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=http://leaver.me/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0>学习笔记</a></span></div><div class=post-content>在kafka快速上手中,留下的问题是关于partition和offset,这篇文章主要解释这个.
Log机制 说到分区,就要说kafka对消息的存储.在官方文档中. 首先,kafka是通过log(日志)来记录消息发布的.每当产生一个消息,kafka会记录到本地的log文件中,这个log和我们平时的log有一定的区别.这里可以参考一下The Log,不多解释.
这个log文件默认的位置在config/server.properties中指定的.默认的位置是log.dirs=/tmp/kafka-logs,linux不用说,windows的话就在你对应磁盘的根目录下.我这里是D盘.
#分区partition# kafka是为分布式环境设计的,因此如果日志文件,其实也可以理解成消息数据库,放在同一个地方,那么必然会带来可用性的下降,一挂全挂,如果全量拷贝到所有的机器上,那么数据又存在过多的冗余,而且由于每台机器的磁盘大小是有限的,所以即使有再多的机器,可处理的消息还是被磁盘所限制,无法超越当前磁盘大小.因此有了partition的概念.
kafka对消息进行一定的计算,通过hash来进行分区.这样,就把一份log文件分成了多份.如上面的分区读写日志图,分成多份以后,在单台broker上,比如快速上手中,如果新建topic的时候,我们选择了--replication-factor 1 --partitions 2,那么在log目录里,我们会看到 test-0目录和test-1目录.就是两个分区了.
你可能会想,这特么没啥区别呀.注意,当有了多个broker之后,这个意义就存在了.这里上一张图,原文在参考链接里有 这是一个topic包含4个Partition，2 Replication(拷贝),也就是说全部的消息被放在了4个分区存储,为了高可用,将4个分区做了2份冗余,然后根据分配算法.将总共8份数据,分配到broker集群上.
结果就是每个broker上存储的数据比全量数据要少,但每份数据都有冗余,这样,一旦一台机器宕机,并不影响使用.比如图中的Broker1,宕机了.那么剩下的三台broker依然保留了全量的分区数据.所以还能使用,如果再宕机一台,那么数据不完整了.当然你可以设置更多的冗余,比如设置了冗余是4,那么每台机器就有了0123完整的数据,宕机几台都行.需要在存储占用和高可用之间做衡量. 至于宕机后,zookeeper会选出新的partition leader.来提供服务.这个等下篇文章
#偏移offset#
上一段说了分区,分区就是一个有序的,不可变的消息队列.新来的commit log持续往后面加数据.这些消息被分配了一个下标(或者偏移),就是offset,用来定位这一条消息.
消费者消费到了哪条消息,是保持在消费者这一端的.消息者也可以控制,消费者可以在本地保存最后消息的offset,并间歇性的向zookeeper注册offset.也可以重置offset
#如何通过offset算出分区#
其实partition存储的时候,又分成了多个segment(段),然后通过一个index,索引,来标识第几段.这里先可以去看一下本地log目录的分区文件夹. 在我这里,test-0,这个分区里面,会有一个index文件和一个log文件, 对于某个指定的分区,假设每5个消息,作为一个段大小,当产生了10条消息的情况想,目前有会得到(只是解释) 0.index (表示这里index是对0-4做的索引) 5.index (表示这里index是对5-9做的索引) 10.index (表示这里index是对10-15做的索引,目前还没满) 和 0.log 5.log 10.log ,当消费者需要读取offset=8的时候,首先kafka对index文件列表进行二分查找,可以算出.应该是在5.index对应的log文件中,然后对对应的5.log文件,进行顺序查找,5->6->7->8,直到顺序找到8就好了.
具体的算法参看美团的文章好了
更多文档 官方文档 Kafka文件存储机制那些事 Kafka集群partition replication自动分配分析 ……</div><p class=readmore><a href=http://leaver.me/2015/09/04/kafka%E4%B8%AD%E7%9A%84partition%E5%92%8Coffset/>阅读全文</a></p></article><article class=post><header><h1 class=post-title><a href=http://leaver.me/2015/09/03/kafka%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B/ title=kafka快速上手>kafka快速上手</a></h1></header><date class="post-meta meta-date">2015年9月3日</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=http://leaver.me/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0>学习笔记</a></span></div><div class=post-content>简单介绍 kafka是一个分布式消息中间件,在kafka中主要涉及到四个基本名词: Topic Kafka将消息种子分门别类， 每一类的消息称之为一个主题(Topic).
Producer 发布消息的对象称之为主题生产者.
Consumer 订阅消息并处理消息的对象称之为主题消费者
Broker 已发布的消息保存在一组服务器中，称之为Kafka集群。集群中的每一个服务器称为一个代理(Broker). 消费者可以订阅一个或多个主题，并从Broker拉数据(注意是拉,不是pull,)，从而消费这些已发布的消息。
安装(以windows为例) 安装非常简单,从这里下载,下载完成后解压到一个目录就好了.
简单使用 首先使用kafka的一个流程就是生产者生产消息,发送给kafka集群,然后消费者从kafka集群中获取消息进行消费. 要启动kafka需要先启动zookeeper,因为ZooKeeper是通过冗余服务实现高可用性的,也就是说在分布式环境中,如何保证kafka集群的高可用.zookeeper会来做leader选取,当消费者准备发消息时,会从zookeeper中获取一个可用的消息服务器地址,然后连接进行发送,保证党集群内有服务器宕机并不影响整体的使用. 1.启动自带的简易zookeeper. 进行解压目录的bin/windows目录 zookeeper-server-start.bat ../../config/zookeeper.properties
执行命令启动,从zookeeper.properties中会看到.zookeeper会开发一个clientPort=2181,2181的端口给消费者使用,其实也可以给生产者使用,但是在0.8.0版本后，producer不再通过zookeeper连接broker, 而是通过brokerlist（192.168.0.1:9092,192.168.0.2:9092,192.168.0.3:9092配置,直接和broker连接，只要能和一个broker连接上就能够获取到集群中其他broker上的信息,绕过了zookeeper.
2.启动kafka服务 kafka-server-start.bat ../../config/server.properties 执行启动,另一个命令行窗口,同样的.查看配置问题,会知道kafka的服务会在port=9092 ,9092端口打开.
3.注册一个topic kafka-topics.bat --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test 这个命令中,create表示创建.zookeeper 和后面的地址表示kafka使用本机2181端口开放的zookeeper保持高可用.replication-factor表示消息只冗余一份,目前我们只有一个kafka机器,broker,partitions 表示一份分区,分区是kafka的另一个概念,大致是说,同一topic内部的消息按照一定的key和算法被分区(partition)存储在不同的位置上，这个下次写好了.这样已经在kafka注册了一个名为test的消息topic了.
4.使用简易的控制台生产者模拟 kafka-console-producer.bat --broker-list localhost:9092 --topic test 前面说过了.新版本生产者直接通过brokerlist来连接kafka,目前只有一台,所以就一个地址,准备向test这个topic发送消息.
5.使用简易的控制台消费者模拟 kafka-console-consumer.bat --zookeeper localhost:2181 --topic test 这个前面也说过了.消费者使用zookeeper获取可用的broker列表,然后拉去消息,并且还有一些offset同步的问题.和分区,文件存储一起的一个概念,下次写.
6.开始生产和消费消息 至此,已经开了四个控制台窗口了..在producer窗口里,随便打几个字,然后enter,在消费者的窗口里将会显示出来. 其他问题 实际可能不那么顺利,如果你启动kafka或者其他应用的时候,有错误提示,提示无法创建虚拟机vm这样的.那么修改一下对应的bat脚本.就好了 ,vm的heap申请是1G,如果你机器内存不够,改成512M,或者更小的就好了.
更多文档 官方文档 kafka快速入门 ……</div><p class=readmore><a href=http://leaver.me/2015/09/03/kafka%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B/>阅读全文</a></p></article><article class=post><header><h1 class=post-title><a href=http://leaver.me/2015/08/08/angularjs-%E5%AD%A6%E4%B9%A0%E8%B5%84%E6%BA%90/ title="AngularJS 学习资源">AngularJS 学习资源</a></h1></header><date class="post-meta meta-date">2015年8月8日</date><div class=post-content>一直对AngularJS很好奇,之前看过国内某在线网站的一套AngularJS教程,可惜没看懂.也没理解为了解决什么问题,只是知道是个前端JS框架.这周看到个Udemy - Learn and Understand AngularJS 这个教程.去看了一下,是收费的.强烈推荐看.无字幕,但是不难,已经看完了.讲的非常非常好.网上有别人分享的.我给个磁力链接吧.
01 Getting Started
02 Model, View, Whatever___
03 Services and Dependency Injection
04 Data Binding and Directives
05 Single Page Applications
06 Custom Services
07 Custom Directives
08 Lets Build an App in record time
09 BONUS Lectures
10 Getting Ready for AngularJS 2.0 in 2016
11 Conclusion
非常的介绍.看完之后,你会理解AngularJS解决了什么问题,他的数据绑定怎么使用,模块怎么弄,怎么写服务,怎么定义指令等等.强烈推荐.
最好有一点js和css的基础会比较好理解.如果懂后端开发的就更好了.依赖注入这些有点基础会比较好理解.……</div><p class=readmore><a href=http://leaver.me/2015/08/08/angularjs-%E5%AD%A6%E4%B9%A0%E8%B5%84%E6%BA%90/>阅读全文</a></p></article><article class=post><header><h1 class=post-title><a href=http://leaver.me/2015/08/07/%E5%85%8D%E8%B4%B9%E7%9A%84%E6%B0%B8%E8%BF%9C%E6%98%AF%E6%9C%80%E8%B4%B5%E7%9A%84/ title=免费的永远是最贵的>免费的永远是最贵的</a></h1></header><date class="post-meta meta-date">2015年8月7日</date><div class=post-content>这周为啥想说这个话题呢,因为我常用的一个专门用来存储照片的酷盘要关闭了,这直接导致的结果就是几十G的照片文件需要自己再下载下来,然后转到另一个地方.之后我会从以下几个方便说起.
我使用过的已经被关闭的服务 我使用过的仍然健在的服务 为什么说免费的就是最贵的 我们应该怎么做 1. 我使用过的已经被关闭的服务 这个先从百度空间说起,在很久很久以前,大概是我高中的时候,很多同学开始在百度空间写文章,我当时对各种各样的小软件比较感兴趣,于是开了个百度空间,专门用来写这个东东.分享各种各样的软件.后来百度空间被个产品经理搞坏,然后被关闭了. 由于分享各种各样的软件.需要有一个提供下载的地方,于是选择了当时很火的千脑网盘这个网盘当时和很多其他网盘一样,下载有收入.刚才去登陆了一下.居然还有点钱.这个网盘现在处于半死不活的状态.印象中好几年没更新了,当时推行的webOS的概念,只能说太超前,技术又不行.搞成现在这样.基本上就是个高级web页面..后来我就清掉了所有数据 当时个人需要保留一些小的精美的软件,于是当时我大联想推出了一个联想网盘,当时大概是500M的额度,承诺免费永久使用,结果内测期结束没过多久,先是暂停上传,然后取消了个人服务.嗯嗯.从此联想一生黑
什么坚果云之类的我就更不说了.
然后使用了酷盘.原因不多解释,目前他就是那个样子了.说个细节.酷盘在第一次关闭的时候没有声明中的FAQ,只有道歉,没有后续解决方案,相当差劲.后来才加上的FAQ.一旦道歉,说明对方对不起你,要坑你,这句话谁说的来着,大体是对的.
Google Reader.这个不多说.还有云诺,这个厂商更是垃圾,我记得没用几天,就关闭了.然后CEO出来哭,说是大家要理解. 不要在宣传的时候说的天花乱坠,永远免费,绝不关闭,而在关闭的时候说的文艺,煽情,多么不舍,最长久的是默默的陪伴.你说的这么煽情,这么文艺不就是为了坑么.
2. 我使用过的仍然健在的服务 Dropbox,dropbox由于国内访问不畅,已经基本不使用了,但是,Dropbox服务非常长久稳定.空间不大,但是绝对良心.好用.
Google相册,好用.智能,空间不大.前段时间无意在Google相册里发现7年前的一张照片.当时的感觉就是还是Google靠谱.好吧,其实Google也不靠谱.Google Reader的关闭就是个坑.
印象笔记,这小伙貌似最近也顶不住的样子,国内弹购买方案的频率现在极其高.可是免费的我真的够用了..如果哪天超过了免费额度,就买收费额度.
3. 为什么说免费的就是最贵的 免费的产品.那么使用者就是真正的产品.通过这些免费的反馈途径,免费的bug提供者,由于是免费,出现损失可以不赔偿,丢了自负,一旦关闭,使用者需要承受迁移的成本,数据丢失的风险.这个体会最深的就是科学上网了.之前一直找各种工具,各种方法,结果大部分时间耗费上找所谓稳定的那啥,想来花费的时间多看点书,写点代码,也值回来了.最后花点钱买个稳定的,有啥问题,卖方也有责任解决,大家干好自己的事情就好了.非常方便.
4. 我们应该怎么做 买,买,买,任何东西,只有付费,才能享受更好的服务.才能有更稳定的服务,才能有售后支持,和赔偿,不论是科学上网,还是云端存储,还是其他任何东西.有钱的捧个钱厂,没钱的捧个小钱厂.
在服务选择上,国外收费>国外免费>国内收费>国内免费.
目前计划先迁移到百度云上,同时同步到Google相册,然后看条件是不是买个主机,搞个私有云.……</div><p class=readmore><a href=http://leaver.me/2015/08/07/%E5%85%8D%E8%B4%B9%E7%9A%84%E6%B0%B8%E8%BF%9C%E6%98%AF%E6%9C%80%E8%B4%B5%E7%9A%84/>阅读全文</a></p></article><article class=post><header><h1 class=post-title><a href=http://leaver.me/2015/07/12/%E6%89%A7%E8%A1%8C%E7%AE%80%E5%8D%95sql%E7%9A%84%E5%B0%8F%E5%B7%A5%E5%85%B7/ title=执行简单sql的小工具>执行简单sql的小工具</a></h1></header><date class="post-meta meta-date">2015年7月12日</date><div class=post-meta><span>|</span>
<span class=meta-category><a href=http://leaver.me/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0>学习笔记</a></span></div><div class=post-content>工作过程中,有时候需要在本地执行一些简单的sql,但是不想下载太大的mysql这类客户端.恰好看到https://code.google.com/p/java-ascii-table/,完美辅助,于是写个了简单的工具.应该是支持sqlserver,oracle,和mysql的.mysql的测试了.其他的没有测试.还要继续完善.已经放在了github上.
代码很简单.就不贴了.
使用说明 先打包,然后https://github.com/leizhiyuan/sqlclient/blob/master/README.md 根据不同的情况写几个简单的bat就可以了.
mysql java -jar sqlclient.jar -u "jdbc:mysql://localhost:3306/mysql" -n "name" -p "pass" -d "com.mysql.jdbc.Driver" oracle java -jar sqlclient.jar -u "jdbc:oracle:thin:@127.0.0.1:1521:XE" -n "name" -p "pass" -d "oracle.jdbc.driver.OracleDriver" sqlserver java -jar sqlclient.jar -u "jdbc:jtds:sqlserver://localhost:1433/sqlserver" -n "name" -p "pass" -d "net.sourceforge.jtds.jdbc.Driver" 截图 交互式执行截图 普通执行截图 引用 java-ascii-table项目 commons-cli命令行解析 ……</div><p class=readmore><a href=http://leaver.me/2015/07/12/%E6%89%A7%E8%A1%8C%E7%AE%80%E5%8D%95sql%E7%9A%84%E5%B0%8F%E5%B7%A5%E5%85%B7/>阅读全文</a></p></article><ol class=page-navigator><li class=prev><a href=http://leaver.me/post/page/4/>上一页</a></li><li><a href=http://leaver.me/post/>1</a></li><li><span>...</span></li><li><a href=http://leaver.me/post/page/3/>3</a></li><li><a href=http://leaver.me/post/page/4/>4</a></li><li class=current><a href=http://leaver.me/post/page/5/>5</a></li><li><a href=http://leaver.me/post/page/6/>6</a></li><li><a href=http://leaver.me/post/page/7/>7</a></li><li><span>...</span></li><li><a href=http://leaver.me/post/page/32/>32</a></li><li class=next><a href=http://leaver.me/post/page/6/>下一页</a></li></ol></div></div><div id=secondary><section class=widget><form id=search action=http://leaver.me/search/ method=get accept-charset=utf-8 target=_blank _lpchecked=1><input type=text name=q maxlength=20 placeholder=Search>
<input type=hidden name=sitesearch value=http://leaver.me/>
<button type=submit class="submit icon-search"></button></form></section><section class=widget><h3 class=widget-title>最近文章</h3><ul class=widget-list><li><a href=http://leaver.me/2020/01/10/mysql%E4%B8%AD%E7%9A%84b-%E6%A0%91%E4%BB%8B%E7%BB%8D/ title=Mysql中的B+树介绍>Mysql中的B+树介绍</a></li><li><a href=http://leaver.me/2020/01/08/2019-%E5%B9%B4%E7%BB%88%E6%80%BB%E7%BB%93/ title="2019 年终总结">2019 年终总结</a></li><li><a href=http://leaver.me/2020/01/06/%E7%90%86%E8%A7%A3-cap-%E7%90%86%E8%AE%BA/ title="理解 CAP 理论">理解 CAP 理论</a></li><li><a href=http://leaver.me/2019/12/30/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3raft%E5%8D%8F%E8%AE%AE/ title=深入理解Raft协议>深入理解Raft协议</a></li><li><a href=http://leaver.me/2019/10/27/%E9%9D%9E%E6%9A%B4%E5%8A%9B%E6%B2%9F%E9%80%9A%E7%AC%94%E8%AE%B0/ title=《非暴力沟通》笔记>《非暴力沟通》笔记</a></li><li><a href=http://leaver.me/2019/10/06/wedding-of-friends/ title="Wedding of Friends">Wedding of Friends</a></li><li><a href=http://leaver.me/2019/09/29/principle-note/ title="Principle Note">Principle Note</a></li><li><a href=http://leaver.me/2019/09/14/%E6%A2%A6%E8%A7%81%E9%B2%B8%E9%B1%BC%E7%9A%84%E9%82%A3%E4%B8%80%E5%A4%9C/ title=梦见鲸鱼的那一夜>梦见鲸鱼的那一夜</a></li><li><a href=http://leaver.me/2019/08/20/understand-hong-kong-2/ title="Understand Hong Kong 2">Understand Hong Kong 2</a></li><li><a href=http://leaver.me/2019/08/18/understand-hong-kong-part-1/ title="Understand Hong Kong Part 1">Understand Hong Kong Part 1</a></li></ul></section><section class=widget><h3 class=widget-title>分类</h3><ul class=widget-list><li><a href=http://leaver.me/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/>学习笔记 (188)</a></li><li><a href=http://leaver.me/categories/%E6%88%91%E7%9A%84%E7%BF%BB%E8%AF%91/>我的翻译 (57)</a></li><li><a href=http://leaver.me/categories/%E6%96%87%E7%AB%A0%E6%94%B6%E8%97%8F/>文章收藏 (53)</a></li><li><a href=http://leaver.me/categories/%E7%94%9F%E6%B4%BB%E8%AE%B0%E5%BD%95/>生活记录 (3)</a></li><li><a href=http://leaver.me/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/>读书笔记 (4)</a></li></ul></section><section class=widget><h3 class=widget-title>标签</h3><div class=tagcloud><a href=http://leaver.me/tags/algorithm/>algorithm</a>
<a href=http://leaver.me/tags/android/>android</a>
<a href=http://leaver.me/tags/c/>C＃</a>
<a href=http://leaver.me/tags/c++/>C++</a>
<a href=http://leaver.me/tags/database/>database</a>
<a href=http://leaver.me/tags/java/>java</a>
<a href=http://leaver.me/tags/javascript/>javascript</a>
<a href=http://leaver.me/tags/linux/>linux</a>
<a href=http://leaver.me/tags/mac/>mac</a>
<a href=http://leaver.me/tags/matlab/>matlab</a>
<a href=http://leaver.me/tags/maven/>maven</a>
<a href=http://leaver.me/tags/mysql/>mysql</a>
<a href=http://leaver.me/tags/nextgen-gallery/>NextGEN Gallery</a>
<a href=http://leaver.me/tags/php/>php</a>
<a href=http://leaver.me/tags/python/>python</a>
<a href=http://leaver.me/tags/shell/>shell</a>
<a href=http://leaver.me/tags/spring/>spring</a>
<a href=http://leaver.me/tags/sql/>sql</a>
<a href=http://leaver.me/tags/stackoverflow/>stackoverflow</a>
<a href=http://leaver.me/tags/wcf/>WCF</a>
<a href=http://leaver.me/tags/web/>web</a>
<a href=http://leaver.me/tags/windows/>windows</a>
<a href=http://leaver.me/tags/wordpress/>wordpress</a>
<a href=http://leaver.me/tags/wpf/>WPF</a>
<a href=http://leaver.me/tags/%E4%B8%8A%E6%B5%B7/>上海</a>
<a href=http://leaver.me/tags/%E4%B8%8B%E8%BD%BD/>下载</a>
<a href=http://leaver.me/tags/%E4%B8%AD%E9%97%B4%E4%BB%B6/>中间件</a>
<a href=http://leaver.me/tags/%E4%BA%92%E8%81%94%E7%BD%91/>互联网</a>
<a href=http://leaver.me/tags/%E5%88%86%E5%B8%83%E5%BC%8F/>分布式</a>
<a href=http://leaver.me/tags/%E5%88%B6%E5%BA%A6/>制度</a>
<a href=http://leaver.me/tags/%E5%89%8D%E7%AB%AF/>前端</a>
<a href=http://leaver.me/tags/%E5%8E%9F%E5%88%9B/>原创</a>
<a href=http://leaver.me/tags/%E5%A4%A7%E5%AD%A6/>大学</a>
<a href=http://leaver.me/tags/%E5%AD%A6%E4%B9%A0/>学习</a>
<a href=http://leaver.me/tags/%E5%AE%89%E5%85%A8/>安全</a>
<a href=http://leaver.me/tags/%E5%AE%B6%E5%BA%AD/>家庭</a>
<a href=http://leaver.me/tags/%E5%B7%A5%E4%BD%9C/>工作</a>
<a href=http://leaver.me/tags/%E5%B7%A5%E5%85%B7/>工具</a>
<a href=http://leaver.me/tags/%E5%B9%B6%E5%8F%91/>并发</a>
<a href=http://leaver.me/tags/%E5%BA%8F%E5%88%97%E5%8C%96/>序列化</a>
<a href=http://leaver.me/tags/%E5%BC%80%E5%8F%91/>开发</a>
<a href=http://leaver.me/tags/%E5%BF%83%E7%90%86/>心理</a>
<a href=http://leaver.me/tags/%E6%80%BB%E7%BB%93/>总结</a>
<a href=http://leaver.me/tags/%E6%8A%80%E6%9C%AF/>技术</a>
<a href=http://leaver.me/tags/%E6%8F%92%E4%BB%B6/>插件</a>
<a href=http://leaver.me/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/>操作系统</a>
<a href=http://leaver.me/tags/%E6%94%B6%E8%97%8F/>收藏</a>
<a href=http://leaver.me/tags/%E6%95%B0%E5%AD%A6/>数学</a>
<a href=http://leaver.me/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/>数据库</a>
<a href=http://leaver.me/tags/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/>数据挖掘</a>
<a href=http://leaver.me/tags/%E6%96%87%E7%AB%A0/>文章</a>
<a href=http://leaver.me/tags/%E6%99%BA%E8%83%BD/>智能</a>
<a href=http://leaver.me/tags/%E6%9D%82%E6%96%87/>杂文</a>
<a href=http://leaver.me/tags/%E6%AD%A6%E6%B1%89/>武汉</a>
<a href=http://leaver.me/tags/%E6%B1%87%E7%BC%96/>汇编</a>
<a href=http://leaver.me/tags/%E7%88%B1%E6%83%85/>爱情</a>
<a href=http://leaver.me/tags/%E7%90%86%E8%AE%BA/>理论</a>
<a href=http://leaver.me/tags/%E7%94%9F%E4%BA%A7%E5%8A%9B/>生产力</a>
<a href=http://leaver.me/tags/%E7%94%9F%E6%B4%BB/>生活</a>
<a href=http://leaver.me/tags/%E7%94%B5%E5%AD%90%E4%B9%A6/>电子书</a>
<a href=http://leaver.me/tags/%E7%94%B5%E5%BD%B1/>电影</a>
<a href=http://leaver.me/tags/%E7%A4%BE%E4%BC%9A/>社会</a>
<a href=http://leaver.me/tags/%E7%A7%91%E6%8A%80/>科技</a>
<a href=http://leaver.me/tags/%E7%AC%94%E8%AE%B0/>笔记</a>
<a href=http://leaver.me/tags/%E7%AE%97%E6%B3%95/>算法</a>
<a href=http://leaver.me/tags/%E7%BC%96%E7%A8%8B/>编程</a>
<a href=http://leaver.me/tags/%E7%BC%96%E8%AF%91/>编译</a>
<a href=http://leaver.me/tags/%E7%BF%BB%E8%AF%91/>翻译</a>
<a href=http://leaver.me/tags/%E8%81%8C%E4%B8%9A/>职业</a>
<a href=http://leaver.me/tags/%E8%AE%B0%E5%BD%95/>记录</a>
<a href=http://leaver.me/tags/%E8%AE%BE%E8%AE%A1/>设计</a>
<a href=http://leaver.me/tags/%E8%AF%BB%E4%B9%A6/>读书</a>
<a href=http://leaver.me/tags/%E8%BD%AF%E4%BB%B6/>软件</a>
<a href=http://leaver.me/tags/%E8%BD%AF%E4%BB%B6%E6%B5%8B%E8%AF%95/>软件测试</a>
<a href=http://leaver.me/tags/%E8%BF%90%E7%BB%B4/>运维</a>
<a href=http://leaver.me/tags/%E9%87%91%E8%9E%8D/>金融</a></div></section><section class=widget><h3 class=widget-title>友情链接</h3><ul class=widget-list><li><a target=_blank href=https://www.cppfans.org/ title=C++爱好者博客>C++爱好者博客</a></li><li><a target=_blank href=http://www.kailing.pub title=KL，每天进步一点点>KL，每天进步一点点</a></li></ul></section><section class=widget><h3 class=widget-title>其它</h3><ul class=widget-list><li><a href=http://leaver.me/index.xml>文章 RSS</a></li></ul></section></div></div></div></div><footer id=footer><div class=container>&copy; 2020 <a href=http://leaver.me/>bystander's blog By bystander</a>.
Powered by <a rel="nofollow noreferer noopener" href=https://gohugo.io target=_blank>Hugo</a>.
<a href=https://www.flysnow.org/ target=_blank>Theme</a> based on <a href=https://github.com/flysnow-org/maupassant-hugo target=_blank>maupassant</a>.</div></footer><a id=rocket href=#top></a><script type=text/javascript src="/js/totop.js?v=0.0.0" async></script><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;ga('create','UA-30961201-3','auto');ga('send','pageview');}</script><script async src=https://www.google-analytics.com/analytics.js></script></body></html>